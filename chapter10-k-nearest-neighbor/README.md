# Chapter 10 Notes

## K Nearest Neighbor

* KNN is used for classification of objects (especially similar objects)
* isolate and evaluate features that are comparable
* use the pythagorean's theorem for each dimension/features compared
* eg: square root ( (x1 - x2)^2 + (y1 - y2)^2 ) = similarity (distance) between the two objects being compared
* cosine similarity is another way to compare rather than values compare slopes to find similarity
* it's important to pick good features, things that don't overlap too much so you can get a good impression to make better recommendations
* uses include: spam filters, OCR, computer vision to identify objects, recommendations
* Classification: categorization into a group
* Regression: predicting a response


### Regression

* used for recommendation base on similarity; if you like these, compare similar people and recommend things they like that you haven't seen yet

